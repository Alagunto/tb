---
description: Self-Correction Loop - Iterative refinement based on review feedback
alwaysApply: true
---

# Self-Correction Loop

After receiving review feedback, you MUST systematically fix identified issues through an iterative refinement process. This rule defines how to parse review results, prioritize fixes, apply corrections, and verify improvements.

## Correction Workflow

### 1. Parse Review Output

When you receive review agent output, extract structured findings:

```
For each finding, capture:
- Severity: CRITICAL | HIGH | MEDIUM | LOW | INFORMATIONAL
- Category: Bug | Security | Performance | Quality | Testing | EdgeCase
- File: path/to/file.ext
- Line: line number(s)
- Description: what's wrong
- Impact: consequences
- Recommendation: how to fix
```

### 2. Prioritize Fixes

Process findings in this strict order:

1. **CRITICAL** - Immediate security threats, data loss risks, system crashes
2. **HIGH** - Significant bugs, authentication issues, major performance problems
3. **MEDIUM** - Moderate bugs, code quality issues, testing gaps
4. **LOW** - Minor improvements, style issues, documentation
5. **INFORMATIONAL** - Observations, best practices

### 3. Apply Fixes Iteratively

**For CRITICAL and HIGH severity**:

```markdown
For each issue in priority order:
1. Read the file and surrounding context
2. Understand the issue completely
3. Formulate a fix that:
   - Addresses the root cause
   - Doesn't introduce new issues
   - Follows project patterns
   - Is minimal and focused
4. Apply the fix
5. Verify the fix with reasoning:
   - "This fix addresses [issue] by [explanation]"
   - "This won't cause [potential side effect] because [reasoning]"
6. Move to next issue
```

**For MEDIUM and LOW severity**:
- Ask user: "I've identified [N] medium/low severity issues. Should I fix them all, or would you like to review them first?"
- If approved, apply fixes using same process as above

### 4. Verification After Each Fix

After applying fixes, verify:

1. **Syntax**: Does the code compile/parse?
2. **Logic**: Does the fix make sense?
3. **Side Effects**: Did we break anything else?
4. **Completeness**: Is the issue fully resolved?

### 5. Re-Review After Corrections

After completing a correction cycle, ALWAYS re-run the review agent:

```bash
cursor-agent -p "Re-review the recent changes after corrections. Verify:

1. Previous issues are now resolved
2. No new issues were introduced
3. Fixes are complete and correct
4. Code quality improved

Compare against the previous review findings and confirm each issue is addressed.

If any previous issues remain or new issues appeared, report them with the same structured format." --model ${CURSOR_REVIEW_MODEL:-gpt-5-codex-high} --print
```

### 6. Iteration Limit

**Maximum Correction Loops**: 3 iterations

**Iteration Counter**:
- Iteration 1: Initial review → fixes → re-review
- Iteration 2: Re-review → fixes → re-review
- Iteration 3: Re-review → fixes → final review

**After 3 Iterations**:
- If issues remain, present to user:
  ```
  I've completed 3 correction iterations. Remaining issues:
  [List remaining issues]
  
  These may require manual intervention or architectural changes.
  How would you like to proceed?
  ```

### 7. Document Corrections

For each correction made, document in `.cursor/improvement-log.md`:

```markdown
## [TIMESTAMP] - [Task Name]

### Issue Fixed
- **Severity**: [level]
- **Category**: [type]
- **File**: [path]
- **Original Problem**: [description]
- **Fix Applied**: [what was done]
- **Reasoning**: [why this fix works]

### Lesson Learned
[What to avoid in future / pattern to follow]
```

## Handling Different Issue Categories

### Security Issues

When fixing security vulnerabilities:

```
1. Identify the vulnerability type (injection, XSS, hardcoded secret, etc.)
2. Research the proper mitigation (if uncertain, invoke perplexity search)
3. Apply defense-in-depth:
   - Input validation
   - Output encoding
   - Least privilege
   - Secure defaults
4. Verify fix doesn't introduce new vulnerabilities
5. Consider if similar issues exist elsewhere in codebase
```

Example:
```
Issue: Hardcoded API key in config.go
Fix: 
1. Remove hardcoded key
2. Use environment variable
3. Add validation that env var is set
4. Add example .env file
5. Update documentation
6. Search codebase for other hardcoded secrets
```

### Performance Issues

When fixing performance problems:

```
1. Understand current complexity/behavior
2. Identify optimization strategy
3. Implement optimization
4. Verify correctness (behavior unchanged)
5. Estimate performance improvement
6. Consider if similar patterns exist elsewhere
```

Example:
```
Issue: O(n²) nested loop in user search
Fix:
1. Analyze the algorithm
2. Implement hash map for O(n) lookup
3. Test with same inputs to verify correctness
4. Estimate: O(n²) → O(n), 100x faster for 1000 items
5. Search for similar nested loops in codebase
```

### Logic Errors

When fixing bugs:

```
1. Understand the intended behavior
2. Identify where actual behavior deviates
3. Trace the root cause
4. Fix at the source (not the symptom)
5. Add test to prevent regression
6. Verify fix with edge cases
```

Example:
```
Issue: Off-by-one error in pagination
Fix:
1. Intended: Show items 1-10, 11-20, etc.
2. Actual: Showing items 1-10, 10-19 (duplicates item 10)
3. Root cause: offset calculation is `page * limit` should be `(page - 1) * limit`
4. Fix the calculation
5. Add test cases for pages 1, 2, 3
6. Test edge cases: empty results, single page, last page
```

### Code Quality Issues

When improving code quality:

```
1. Identify the quality issue (duplication, complexity, naming, etc.)
2. Refactor while preserving behavior
3. Improve readability and maintainability
4. Follow project conventions
5. Keep changes minimal and focused
```

## Example Complete Correction Cycle

```markdown
### Initial Review Results
- CRITICAL: Hardcoded database password in db.go:23
- HIGH: SQL injection vulnerability in user_query.go:45
- MEDIUM: Duplicate code in handlers.go and utils.go
- LOW: Missing error documentation

### Iteration 1: Fix Critical and High

**Fix 1: Remove hardcoded password**
- Changed db.go:23 to use os.Getenv("DB_PASSWORD")
- Added validation for empty env var
- Updated README with environment setup

**Fix 2: Fix SQL injection**
- Changed user_query.go:45 to use parameterized query
- Changed: `query := "SELECT * FROM users WHERE id = " + userID`
- To: `query := "SELECT * FROM users WHERE id = $1"` with parameter

**Re-Review After Iteration 1**
✅ CRITICAL: Resolved
✅ HIGH: Resolved
⚠️ NEW ISSUE: Missing error handling in env var check
⚠️ MEDIUM: Still present (duplicate code)
- LOW: Still present

### Iteration 2: Fix new issue and Medium issues

**Fix 3: Add error handling**
- Added proper error handling for missing DB_PASSWORD
- Return error instead of panicking

**Fix 4: Extract duplicate code**
- Created shared function in utils.go
- Removed duplication from handlers.go
- Updated both call sites

**Re-Review After Iteration 2**
✅ All CRITICAL and HIGH: Resolved
✅ MEDIUM: Resolved
- LOW: Still present (documentation)

### Iteration 3: Fix remaining LOW issues

**Fix 5: Add documentation**
- Added godoc comments for error returns

**Final Re-Review**
✅ All issues resolved
✅ No new issues introduced
✅ Code quality improved

### Summary
Fixed 5 issues across 3 iterations:
- 1 CRITICAL security issue
- 1 HIGH security issue  
- 2 MEDIUM quality issues
- 1 LOW documentation issue
```

## Success Criteria

A correction cycle is complete when:

✅ All CRITICAL and HIGH issues are resolved
✅ MEDIUM/LOW issues are resolved or user-approved to skip
✅ Re-review confirms no new issues introduced
✅ All fixes are documented in improvement log
✅ Code compiles and tests pass

## Failure Handling

If unable to fix an issue after 3 attempts:

1. Document the issue clearly
2. Explain what was attempted
3. Explain why it failed
4. Ask user for guidance
5. Consider if issue requires architectural changes

## Integration with Other Rules

- **Triggered by**: 02-review-workflow.mdc
- **May trigger**: 05-security-checks.mdc (for security issues)
- **May trigger**: 06-testing-validation.mdc (to verify tests)
- **Updates**: 09-feedback-loop.mdc (improvement log)
- **References**: 00-agent-config.mdc (for iteration limits)

## Notes

- Fixing one issue at a time prevents cascading errors
- Re-review after each cycle catches regression bugs
- Documentation of fixes enables learning and improvement
- Iteration limit prevents infinite loops and excessive costs
- User involvement for MEDIUM/LOW issues maintains control
- Critical and high-severity issues should never be left unfixed
